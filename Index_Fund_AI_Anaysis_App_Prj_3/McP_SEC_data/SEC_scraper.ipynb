{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following notebook code was written and posted under an MIT license,\n",
    "the repo can be found here:\n",
    "\n",
    "\n",
    "https://github.com/KirillTsarapkin/extracting-sec.gov-filings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CIK numbers:\n",
    "# stock ticker: fund name : CIK\n",
    "##### DIA = (dia: spdr dow jones industrial average:  0001041130)\n",
    "##### QQQ = (QQQ: Invesco QQQ Trust, series 1)\n",
    "##### SPY = (SPY:SPDR S&P 500 Trust: 0000884394)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filing types:\n",
    "\n",
    "    - 10-Q: is a company’s quarterly financial report. When traders refer to a company’s “earnings date” or “earnings report,” they are most often referring to the company’s 10-Q filing. The 10-Q report contains information such as a company’s income, its revenue and its debt levels, and it must be filed within 35 days of the end of each quarter.\n",
    "    \n",
    "    - 10-k: A 10-K filing is a company’s annual financial report. A 10-K filing is like a 10-Q on steroids and is typically a much more in-depth report on the business. In addition to all of the standard metrics contained in a 10-Q report, 10-K reports often contain executive compensation figures, audited financial statements, updates about specific business segments or initiatives and commentary on the outlook for the company in the quarters ahead.\n",
    "    \n",
    "    - 8-K: Finally, an 8-K filing is a “real-time” report on any important changes that impact the company. Public companies must inform shareholders immediately of “unscheduled material events that are important to shareholders,” and they do so by disclosing them via 8-K filings. Common unplanned events include business deals, employee layoffs, lawsuits, store or factory closings and bankruptcy filings. It’s common for companies to file a number of 8-K forms throughout a given quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests-random-user-agent\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install contextlib2\n",
    "# !pip install python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variable for CIK codes\n",
    "DIA= '0001041130'\n",
    "SPY= '0000884394'\n",
    "QQQ= '0001067839'\n",
    "ticker_query = ['DIA', 'SPY', 'QQQ']\n",
    "\n",
    "#set variable for report type:\n",
    "# qurterly_reprts= '10-k'\n",
    "# annual_reports= '10-q'\n",
    "# current_reports= '8-k'\n",
    "query_report_type = ['10-K']\n",
    "\n",
    "# set file_path for the output SQlite .db file\n",
    "db_file_path = r'C:\\Users\\mikea\\Desktop\\Dataclass2\\StockPrediction_Project3\\MCP_SEC_data'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path C:\\Users\\mikea\\Desktop\\Dataclass2\\StockPrediction_Project3\\MCP_SEC_data already exists.\n",
      "Could not retrieve the table containing the necessary information.                    \n",
      "Aborting the program.\n",
      "If index list is out of range, make sure                     that you entered the correct CIK number(s).\n",
      "name 'filing_parameters' is not defined\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 100\u001b[0m, in \u001b[0;36mFiling_Links.Get_Filing_Links\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Filing_Type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiling_types:\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# request the url, and then parse the response.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.sec.gov/cgi-bin/browse-edgar\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 100\u001b[0m                             params \u001b[38;5;241m=\u001b[39m filing_parameters)\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Add 0.1 second time delay to comply with SEC.gov's 10 requests per second limit.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filing_parameters' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 594\u001b[0m\n\u001b[0;32m    593\u001b[0m filings1 \u001b[38;5;241m=\u001b[39m Filing_Links(company_CIKs, filing_types, start_date, end_date)\n\u001b[1;32m--> 594\u001b[0m filings1\u001b[38;5;241m.\u001b[39mGet_Filing_Links()\n\u001b[0;32m    595\u001b[0m data1 \u001b[38;5;241m=\u001b[39m Extract_Data()\n",
      "Cell \u001b[1;32mIn[4], line 189\u001b[0m, in \u001b[0;36mFiling_Links.Get_Filing_Links\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not retrieve the table containing the necessary information.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAborting the program.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf index list is out of range, make sure \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124m        that you entered the correct CIK number(s).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 189\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInteractiveTB\u001b[38;5;241m.\u001b[39mget_exception_only(etype,\n\u001b[0;32m   2098\u001b[0m                                                      value))\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FormattedTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1437\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m VerboseTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m   1327\u001b[0m         \u001b[38;5;28mself\u001b[39m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1328\u001b[0m     )\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1174\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(cf\u001b[38;5;241m.\u001b[39mtb_frame)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "\"\"\" the below noptebook is a modified version of the original code from the following \n",
    "link: https://github.com/galibin24/SEC-EDGAR-python-scraper .\n",
    "\n",
    "SEC-EDGAR-python-scraper is licensed under the terms of the MIT license. \"# SEC-EDGAR-python-scraper\" \"\"\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import requests_random_user_agent # pip install requests-random-user-agent\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "import re\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import sys\n",
    "from contextlib import closing # pip install contextlib2\n",
    "import time\n",
    "from dateutil import parser # pip install python-dateutil\n",
    "from datetime import datetime\n",
    "\n",
    "''' this is where you enter in your CIK codes for the companies you want to pull data from the SEC Edgar website. \n",
    "user needs to update the database path, e'''\n",
    "# You can find company's CIK number at https://www.sec.gov/edgar/searchedgar/companysearch.html\n",
    "company_CIKs = [ticker_query]\n",
    "# Enter what forms(s) you want to extract using the '10-K', '10-Q', '8-K' format.\n",
    "filing_types = [query_report_type]\n",
    "# Enter the database name that you want to use and populate.\n",
    "#The database will be automatically created if it does not exist.\n",
    "db_name = 'SEC_edgar_filings.db'\n",
    "# Specify the folder path for DB file. For example \"C:\\sqlite\\db\"\n",
    "folder_path = db_file_path\n",
    "db_path = f\"{folder_path}\\{db_name}\"\n",
    "# Enter the date range for the filings in the 'YYYY-MM-DD' format\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-04-01'\n",
    "\n",
    "\n",
    "'''End of query input. the rest of the code will scrape the SEC Edgar website for the data you requested. create a database\n",
    "in sqlite and populate it with the data. once completed you can use the data for analysis.'''\n",
    "\n",
    "# Create a class to handle connection(s) to SQLite database(s).\n",
    "class DB_Connection:\n",
    "\n",
    "    # Initialize the object's attributes.\n",
    "    def __init__(self, db_name, folder_path, db_path):\n",
    "        self.db_name = db_name\n",
    "        self.folder_path = folder_path\n",
    "        self.db_path = db_path\n",
    "\n",
    "    # Create a directory for the DB file if the directory does not exist.\n",
    "    def create_folder(self):\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            os.makedirs(self.folder_path)\n",
    "            print(f'Successfully created a new folder path {self.folder_path}.')\n",
    "        else:\n",
    "            print(f'Folder path {self.folder_path} already exists.')\n",
    "\n",
    "    # Open connection to the database, if connection fails abort the program.\n",
    "    # If the DB file does not already exist, it will be automatically created.\n",
    "    @classmethod\n",
    "    def open_conn(cls, db_path):\n",
    "        try:\n",
    "            cls.conn = sqlite3.connect(cls.db_path)\n",
    "            print(f'Successfully connected to the {cls.db_path} database.')\n",
    "            return cls.conn\n",
    "        except sqlite3.Error as e:\n",
    "            print(f'Error occurred, unable to connect to the {db_path} database.\\\n",
    "                    \\n{e}\\nAbording program.')\n",
    "            # sys.exit(0) means the program is exiting without any errors\n",
    "            # sys.exit(1) means there was an error.\n",
    "            sys.exit(1)\n",
    "    # Close connection to the database.\n",
    "    @classmethod\n",
    "    def close_conn(cls):\n",
    "        try:\n",
    "            cls.conn.commit()\n",
    "            print('Committed transactions.')\n",
    "            cls.conn.close()\n",
    "            print('Closing all database connections.')\n",
    "        except Exception as e:\n",
    "            print(f'Unable to close database connection.\\n{e}')\n",
    "\n",
    "\n",
    "class Filing_Links:\n",
    "    def __init__(self, company_CIKs, filing_types, start_date, end_date):\n",
    "            self.company_CIKs = company_CIKs\n",
    "            # Capitalize the letters of form type, since by default SQLite is case sensitive.\n",
    "            self.filing_types = [item.upper() for item in filing_types]\n",
    "            self.start_date = start_date\n",
    "            self.end_date = end_date\n",
    "\n",
    "    # Get available filings types for a specific company and their respective links.\n",
    "    def Get_Filing_Links(self):\n",
    "        try:\n",
    "            for Company_CIK_Number in self.company_CIKs:\n",
    "                for Filing_Type in self.filing_types:\n",
    "\n",
    "                    # request the url, and then parse the response.\n",
    "                    response = requests.get(url = r\"https://www.sec.gov/cgi-bin/browse-edgar\",\n",
    "                                            params = filing_parameters)\n",
    "                    # Add 0.1 second time delay to comply with SEC.gov's 10 requests per second limit.\n",
    "                    time.sleep(0.1)\n",
    "                    if response.status_code == 200:\n",
    "                            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    else:\n",
    "                        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "                        continue\n",
    "                    sec_base_url = r\"https://www.sec.gov\"\n",
    "                    # Find the document table that contains filing information.\n",
    "                    main_table = soup.find_all('table', class_='tableFile2')\n",
    "                    # The base URL will be used to construct document links URLs.\n",
    "                    sec_base_url = r\"https://www.sec.gov\"\n",
    "                    Company_Name_path=str(soup.find('span',{'class':'companyName'}))\n",
    "                    if Company_Name_path != None:\n",
    "                        try:\n",
    "                            Company_Name = re.search('<span class=\"companyName\">(.*)<acronym title',\n",
    "                                                    Company_Name_path).group(1)\n",
    "                        except AttributeError:\n",
    "                            print(\"Could not find company name, \\\n",
    "                                assigning NULL value to company name.\")\n",
    "                            Company_Name = None\n",
    "                    # loop through each row of table and extract filing numbers, links, etc.\n",
    "                    for row in main_table[0].find_all('tr'):\n",
    "                        # Your code here\n",
    "                        # find all the rows under the 'td' element.\n",
    "                        cols = row.find_all('td')\n",
    "                        # If no information was detected, move on to the next row.\n",
    "                        if len(cols) != 0:\n",
    "                            # Get the text from the table.\n",
    "                            Filing_Type = cols[0].text.strip()\n",
    "                            Filing_Date = cols[3].text.strip()\n",
    "                            Filing_Number = cols[4].text.strip()\n",
    "                            Filing_Number = ''.join(e for e in Filing_Number if e.isalnum())\n",
    "                            # Get the URL path to the filing number.\n",
    "                            filing_number_path = cols[4].find('a')\n",
    "                            if filing_number_path != None:\n",
    "                                Filing_Number_Link = sec_base_url + filing_number_path['href']\n",
    "                            else:\n",
    "                                break\n",
    "                            # Get the URL path to the document.\n",
    "                            document_link_path = cols[1].find('a',\n",
    "                                                            {'href':True, 'id':'documentsbutton'})\n",
    "                            if document_link_path != None:\n",
    "                                Document_Link = sec_base_url + document_link_path['href']\n",
    "                            else:\n",
    "                                Document_Link = None\n",
    "\n",
    "                            # Get the account number.\n",
    "                            try:\n",
    "                                Account_Number= cols[2].text.strip()\n",
    "                                Account_Number = re.search('Acc-no:(.*)(34 Act)',\n",
    "                                                            Account_Number).group(1)\n",
    "                                Account_Number = ''.join(e for e in Account_Number if e.isalnum())\n",
    "\n",
    "                            except Exception as e:\n",
    "                                \"\"\"\n",
    "                                Add break if you don't want empty account number rows.\n",
    "                                If account number is not present, the interactive document\n",
    "                                link will not be available. If the interactive link is not\n",
    "                                present, we will not be able to extract the individual\n",
    "                                tables containing financial statements..\n",
    "                                \"\"\"\n",
    "                                Account_Number = None\n",
    "                                print(f'Could not retrieve the account number, \\\n",
    "                                        assigning NULL value.\\n{e}')\n",
    "\n",
    "                            # Get the URL path to the interactive document.\n",
    "                            interactive_data_path = cols[1].find('a',\n",
    "                                                                {'href':True, 'id':'interactiveDataBtn'})\n",
    "                            if interactive_data_path != None:\n",
    "                                Interactive_Data_Link = sec_base_url + interactive_data_path['href']\n",
    "                                # If the interactive data link exists, then so does the FilingSummary.xml link.\n",
    "                                Summary_Link_Xml = Document_Link.replace(f\"/{Account_Number}\",'')\\\n",
    "                                                                .replace('-','')\\\n",
    "                                                                .replace('index.htm' ,'/FilingSummary.xml')\n",
    "\n",
    "                            else:\n",
    "                                # break\n",
    "                                Interactive_Data_Link = None\n",
    "                                Summary_Link_Xml = None\n",
    "\n",
    "                            self.info_to_sql(Company_Name, Company_CIK_Number, Account_Number,\n",
    "                                            Filing_Type, Filing_Number, Filing_Date, Document_Link,\n",
    "                                            Interactive_Data_Link, Filing_Number_Link, Summary_Link_Xml)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not retrieve the table containing the necessary information.\\\n",
    "                    \\nAborting the program.\\nIf index list is out of range, make sure \\\n",
    "                    that you entered the correct CIK number(s).\\n{e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Migrate the DataFrame containing, filing and document links information to a local SQLite database.\n",
    "    def info_to_sql(self, Company_Name, Company_CIK_Number, Account_Number,\n",
    "                    Filing_Type, Filing_Number, Filing_Date, Document_Link,\n",
    "                    Interactive_Data_Link, Filing_Number_Link, Summary_Link_Xml):\n",
    "\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS filing_list (\n",
    "                    filing_number integer PRIMARY KEY,\n",
    "                    account_number integer,\n",
    "                    company_name text NOT NULL,\n",
    "                    cik integer NOT NULL,\n",
    "                    filing_type text NOT NULL,\n",
    "                    filing_date text NOT NULL,\n",
    "                    document_link_html TEXT NOT NULL,\n",
    "                    filing_number_link TEXT NOT NULL,\n",
    "                    interactive_dash_link TEXT,\n",
    "                    summary_link_xml TEXT\n",
    "                    )\n",
    "                    ;\"\"\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to create filing_list table.\\\n",
    "                        \\nAbording the program.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                print(\"Successfully created the table.\")\n",
    "                print(f\"Migrating information for filing number {Filing_Number} to the SQL table.......\")\n",
    "                try:\n",
    "                    # INSERT or IGNORE will insert a record if it does NOT duplicate an existing record.\n",
    "                    with closing(conn.cursor()) as cursor:\n",
    "                        cursor.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT or IGNORE INTO filing_list (\n",
    "                        filing_number,\n",
    "                        account_number,\n",
    "                        company_name,\n",
    "                        cik,\n",
    "                        filing_type,\n",
    "                        filing_date,\n",
    "                        document_link_html,\n",
    "                        filing_number_link,\n",
    "                        interactive_dash_link,\n",
    "                        summary_link_xml\n",
    "                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?) \"\"\"\n",
    "                        ,(\n",
    "                        Filing_Number,\n",
    "                        Account_Number,\n",
    "                        Company_Name,\n",
    "                        Company_CIK_Number,\n",
    "                        Filing_Type,\n",
    "                        Filing_Date,\n",
    "                        Document_Link,\n",
    "                        Filing_Number_Link,\n",
    "                        Interactive_Data_Link,\n",
    "                        Summary_Link_Xml\n",
    "                        ))\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error occurred while attempting to insert values into the filing_list table.\\n{e}\")\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "    # Extract individual table links to financial statements, supplementary data tables, etc\n",
    "    def get_table_links(self):\n",
    "        dfs = []\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                for Company_CIK_Number in self.company_CIKs:\n",
    "                    for Filing_Type in self.filing_types:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT filing_number, summary_link_xml\n",
    "                            FROM filing_list\n",
    "                            WHERE summary_link_xml IS NOT NULL\n",
    "                            AND filing_type = ?\n",
    "                            AND cik = ?\n",
    "                            AND filing_date BETWEEN ? AND ?\n",
    "                            \"\"\", con = conn , params=(Filing_Type,\n",
    "                                                    Company_CIK_Number,\n",
    "                                                    self.start_date,\n",
    "                                                    self.end_date))\n",
    "                        dfs.append(df)\n",
    "                df_query2 = pd.concat(dfs)\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to retrieve data from the filing_list table.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            # If the DataFrame is empty, terminate the program.\n",
    "            if len(df_query2) == 0:\n",
    "                print('DataFrame is empty, aborting the program.\\nAbording the program.')\n",
    "                sys.exit(1)\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS individual_report_links (\n",
    "                    filing_number integer,\n",
    "                    short_name text,\n",
    "                    report_url text,\n",
    "                    FOREIGN KEY(filing_number) REFERENCES filing_list(filing_number),\n",
    "                    UNIQUE(report_url)\n",
    "                    )\n",
    "                    ;\"\"\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to create individual_report_links table.\\\n",
    "                        \\nAbording the program.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            # Extract the tables name and its respective URL\n",
    "            # Currently, I do not have a function/method to extract data from a .XML file extension.\n",
    "            for filing_number, summary_link_xml in df_query2.itertuples(index = False):\n",
    "                response_2 = requests.get(summary_link_xml).content\n",
    "                time.sleep(0.1)\n",
    "                soup_2 = BeautifulSoup(response_2, 'lxml')\n",
    "                for item in soup_2.find_all('report')[:-1]:\n",
    "                    if item.shortname:\n",
    "                        Short_Name = item.shortname.text\n",
    "                        # Remove special characters\n",
    "                        Short_Name = re.sub(r\"[^a-zA-Z0-9]+\", ' ', Short_Name)\n",
    "                        # Remove white wite space at the end of the string.\n",
    "                        Short_Name = Short_Name.rstrip()\n",
    "                    else:\n",
    "                        print('Short name could not be retrieved.')\n",
    "                        Short_Name  = None\n",
    "                    # Some tables come only in the xml form.\n",
    "                    if item.htmlfilename:\n",
    "                        Report_Url = summary_link_xml.replace('FilingSummary.xml',\n",
    "                                                            item.htmlfilename.text)\n",
    "                    elif item.xmlfilename:\n",
    "                        Report_Url = summary_link_xml.replace('FilingSummary.xml',\n",
    "                                                            item.xmlfilename.text)\n",
    "                    else:\n",
    "                        print('URL to the individual report could not be retrieved.')\n",
    "                        Report_Url = None\n",
    "                    print(Short_Name)\n",
    "                    print(Report_Url)\n",
    "                    print(filing_number)\n",
    "                    print('*'*50 + ' Inserting values into the table .... ' + '*'*50)\n",
    "                    try:\n",
    "                        with closing(conn.cursor()) as cursor:\n",
    "                            cursor.execute(\n",
    "                            \"\"\"\n",
    "                            INSERT OR IGNORE INTO individual_report_links (\n",
    "                            filing_number,\n",
    "                            short_name,\n",
    "                            report_url\n",
    "                            ) VALUES (?, ?, ?) \"\"\",(\n",
    "                            filing_number,\n",
    "                            Short_Name,\n",
    "                            Report_Url\n",
    "                            ))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error occurred while attempting to insert values into \\\n",
    "                                the individual_report_links table.\\nAbording the program.\\n{e}\")\n",
    "                        sys.exit(1)\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "\n",
    "class Extract_Data:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_xml = None\n",
    "    # Extract table data from a .XMK\n",
    "    def htm_table_extractor(self,report_url):\n",
    "        # Note to self, .text is in Unicode, .content is in bytes.\n",
    "        response_xml = requests.get(report_url).content\n",
    "        time.sleep(0.1)\n",
    "        soup_xml = BeautifulSoup(response_xml, \"lxml\")\n",
    "        table = soup_xml.find_all('table')\n",
    "        if table:\n",
    "            try:\n",
    "                print(\"Inserting table data into the DataFrame.\")\n",
    "                self.df_xml = pd.read_html(str(table))[0]\n",
    "                self.df_xml = self.df_xml.replace({'\\$':''}, regex = True)\\\n",
    "                                        .replace({'\\)':''}, regex = True)\\\n",
    "                                        .replace({'\\(':''}, regex = True)\\\n",
    "                                        .replace({'\\%':''}, regex = True)\\\n",
    "                                        .replace({' ','', 1}, regex = True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error occurred while attempting to insert \\\n",
    "                        table data into the DataFrame.\\n{e}')\n",
    "        else:\n",
    "            print(f'No table detected for {report_url}.')\n",
    "\n",
    "    # Retreive the necessary information information to extract data from the table's URL.\n",
    "    def get_tables(self):\n",
    "        dfs =[]\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            # SOL query to get data\n",
    "            tuple_variable = ...\n",
    "            expected_length = ...\n",
    "            try:\n",
    "                if 'table_name' not in locals():\n",
    "                    table_name = 'Unknown'\n",
    "                    if len(tuple_variable) >= expected_length:\n",
    "                # safe to access tuple_variable[index]\n",
    "                # Example of ensuring date format\n",
    "                #from datetime import datetime\n",
    "                        start_date = datetime.strptime(start_date, '%Y-%m-%d').date() if isinstance(start_date, str) else start_date\n",
    "                        end_date = datetime.strptime(end_date, '%Y-%m-%d').date() if isinstance(end_date, str) else end_date\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to retreive data from the SQL database.\\nAbording the program.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "            for company_CIK in filings1.company_CIKs:\n",
    "                for filing_type in filings1.filing_types:\n",
    "                    try:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT a.filing_number,\n",
    "                                a.company_name,\n",
    "                                a.filing_type,\n",
    "                                a.filing_date,\n",
    "                                b.short_name ,\n",
    "                                b.report_url\n",
    "                            FROM filing_list a\n",
    "                            INNER JOIN individual_report_links b\n",
    "                            ON a.filing_number = b.filing_number\n",
    "                            WHERE b.report_url LIKE '%.htm%'\n",
    "                            AND a.cik = ?\n",
    "                            AND a.filing_type = ?\n",
    "                            AND a.filing_date BETWEEN ? AND ?\n",
    "                            ORDER by filing_date DESC\n",
    "                            LIMIT ?\n",
    "                            \"\"\", con = conn , params=(company_CIK, filing_type,\n",
    "                                                    filings1.start_date,\n",
    "                                                    filings1.end_date , 10))\n",
    "                        dfs.append(df)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error occurred while attempting to retreive data \\\n",
    "                                from the SQL database.\\nAbording the program.\\n{e}\")\n",
    "                        sys.exit(1)\n",
    "            df_query1 = pd.concat(dfs)\n",
    "            # If the DataFrame is empty, terminate the program.\n",
    "            if len(df_query1) == 0:\n",
    "                print('DataFrame is empty, aborting the program.\\nAbording the program.')\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                # If maximum recursion error occurs, increase recursion limit. sys.setrecursionlimit(25000)\n",
    "                pass\n",
    "            for filing_number,\\\n",
    "                company_name,\\\n",
    "                filing_type,\\\n",
    "                filing_date,\\\n",
    "                short_name,\\\n",
    "                report_url in df_query1.itertuples(index = False):\n",
    "                print(f'Processing {short_name} table at {report_url}.')\n",
    "\n",
    "                if report_url.endswith('.htm'):\n",
    "                    try:\n",
    "                        self.htm_table_extractor(report_url)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Could not retreive the table for filing number \\\n",
    "                                {filing_number} at {report_url}\\n{e}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        try:\n",
    "                            # We want to name the table with a unique table name for easy reference.\n",
    "                            table_name = filing_type + filing_date + '_' + \\\n",
    "                                        short_name.replace(' ','_') + '_' + str(filing_number)\n",
    "                            # Remove all special characters except for '_'\n",
    "                            table_name = re.sub(r\"[^a-zA-Z0-9]+\", '_', table_name)\n",
    "                            print(f'Inserting data from the DataFrame into SQL table {table_name}')\n",
    "                            # Check to see if table already exists in the database to avoid duplicate records.\n",
    "                            with closing(conn.cursor()) as cursor:\n",
    "                                cursor.execute(f\"\"\" SELECT count(name)\n",
    "                                            FROM sqlite_master\n",
    "                                            WHERE type='table' AND name= '{table_name}' \"\"\") # SQL injection vulnerability.\n",
    "                                # If count is 1, then table exists\n",
    "                                if cursor.fetchone()[0]==1:\n",
    "                                    print(f'Table {table_name} already exists.')\n",
    "                                else:\n",
    "                                    # Write records that are stored in the DataFrame into a SQL server database.\n",
    "                                    self.df_xml.to_sql(con = conn,\n",
    "                                            name=table_name,\n",
    "                                            schema='SCHEMA',\n",
    "                                            index=False,\n",
    "                                            if_exists='fail')\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Could not migrate the {short_name} table to the SQL database.\\n{e}\")\n",
    "                elif report_url.endswith('.xml'):\n",
    "                    print('.xml extension link detected. Unable to to process the table.\\\n",
    "                        \\n.xml extension link support is expected to be developed in the future.')\n",
    "                else:\n",
    "                    print(f'Table for filing number {filing_number} could not be detected.')\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "\n",
    "    # Normalize the data.\n",
    "    def transpose(self):\n",
    "\n",
    "        db2_path = db_path.replace('.db','_transposed.db')\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                df_table_list = pd.read_sql_query(\n",
    "                \"\"\"\n",
    "                SELECT name AS table_name\n",
    "                FROM sqlite_master\n",
    "                WHERE type='table'\n",
    "                \"\"\", conn)\n",
    "            except ValueError as e:\n",
    "                print(f\"Could not retrieve table list.\\n{e}\")\n",
    "            for row in df_table_list.itertuples(index = False):\n",
    "                try:\n",
    "                    df_table = pd.read_sql_query(\n",
    "                    \"\"\" SELECT * FROM \"{}\" \"\"\".format(row.table_name), con=conn)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Could not read table {table_name}.\\n{e}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        while row.table_name not in ['filing_list', 'individual_report_links']:\n",
    "                            # Remove duplicate rows that have the same values.\n",
    "                            df_table = df_table.drop_duplicates()\n",
    "                            # Transpose the pandas DataFrame.\n",
    "                            df_table = df_table.T\n",
    "                            # Transform first rows into the header.\n",
    "                            df_table.columns = df_table.iloc[0]\n",
    "                            df_table = df_table[1:]\n",
    "                            # Remove special characters, replace empty spaces with _\n",
    "                            df_table = df_table.rename(columns=lambda x: re.sub('\\W+','_',str(x)))\n",
    "                            df_table.columns = df_table.columns.str.strip('_')\n",
    "                            df_table.columns = df_table.columns.str.lower()\n",
    "                            # Convert index of the DataFrame into a column.\n",
    "                            df_table.reset_index(level=0, inplace=True)\n",
    "                            # Format the date column.\n",
    "                            try:\n",
    "                                date_list = []\n",
    "                                for item in df_table.iloc[:,0]:\n",
    "                                    match = re.search('\\D{3}. \\d{2}, \\d{4}', item)\n",
    "                                    if match is not None:\n",
    "                                        # .strftime removes the time stamp.\n",
    "                                        date= parser.parse(match.group()).strftime(\"%Y-%m-%d\")\n",
    "                                        date_list.append(date)\n",
    "                                    else:\n",
    "                                        date_list.append(item)\n",
    "                                df_table.rename(columns={ df_table.columns[0]: \"date\" }, inplace = True)\n",
    "                                df_table['date'] = date_list\n",
    "                                print('Successfully formatted the date.')\n",
    "                            except Exception as e:\n",
    "                                df_table.rename(columns={ df_table.columns[0]: \"name\" }, inplace = True)\n",
    "                                print(e)\n",
    "\n",
    "                            # Convert rows to numeric data types such as integers and floats.\n",
    "                            df_table.replace(',','', regex=True, inplace=True)\n",
    "                            df_table = df_table.apply(pd.to_numeric, errors = 'ignore')\n",
    "                            # Dynamically rename duplicate rows that have the same name.\n",
    "                            if any(df_table.columns.duplicated()):\n",
    "                                print('Duplicate column name detected.\\nRenaming the duplicate column name.  ')\n",
    "                                columns_series = pd.Series(df_table.columns)\n",
    "                                for dup in columns_series[columns_series.duplicated()].unique():\n",
    "                                    columns_series[columns_series[columns_series == dup].index.values.tolist()] = \\\n",
    "                                    [dup + '.' + str(i) if i != 0 else dup for i in range(sum(columns_series == dup))]\n",
    "                                df_table.columns = columns_series\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not transpose the table.\\n{e}\")\n",
    "                    else:\n",
    "                        with DB_Connection.open_conn(db2_path) as conn2:\n",
    "                            # Check to see if table already exists in the database.\n",
    "                            with closing(conn2.cursor()) as cursor:\n",
    "                                cursor.execute(f\"\"\" SELECT count(name)\n",
    "                                            FROM sqlite_master\n",
    "                                            WHERE type='table' AND name= '{row.table_name}' \"\"\") # SQL injection vulnerability.\n",
    "                                # If count is 1, then table exists\n",
    "                                if cursor.fetchone()[0]==1 and row.table_name not in ['filing_list', 'individual_report_links']:\n",
    "                                    print(f'Table {row.table_name} already exists.')\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        print(f'Connected to the {db2_path} database.')\n",
    "                                        print(f'Inserting data from the DataFrame into SQL table {row.table_name}')\n",
    "                                        # Write records that are stored in the DataFrame into a SQL server database.\n",
    "                                        df_table.to_sql(con = conn2,\n",
    "                                                        name = row.table_name,\n",
    "                                                        schema ='SCHEMA',\n",
    "                                                        if_exists = 'replace',\n",
    "                                                        index = False\n",
    "                                                        )\n",
    "\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Could not migrate the {row.table_name} table to the normalized SQL database.\\n{e}\")\n",
    "        DB_Connection.close_conn()\n",
    "# copilot correction, added the following code to convert the company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "# # Convert company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "# company_CIKs = str(company_CIKs) if isinstance(company_CIKs, list) else company_CIKs\n",
    "# filing_types = str(filing_types) if isinstance(filing_types, list) else filing_types\n",
    "# start_date = str(start_date) if isinstance(start_date, list) else start_date\n",
    "# end_date = str(end_date) if isinstance(end_date, list) else end_date\n",
    "\n",
    "\n",
    "# Convert company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "company_CIKs = str(company_CIKs) if isinstance(company_CIKs, list) else company_CIKs\n",
    "filing_types = str(filing_types) if isinstance(filing_types, list) else filing_types\n",
    "start_date = str(start_date) if isinstance(start_date, list) else start_date\n",
    "end_date = str(end_date) if isinstance(end_date, list) else end_date\n",
    "\n",
    "connection1 = DB_Connection('SEC_edgar_filings.db', r'C:\\Users\\mikea\\Desktop\\Dataclass2\\StockPrediction_Project3\\MCP_SEC_data', r'C:\\Users\\mikea\\Desktop\\Dataclass2\\StockPrediction_Project3\\MCP_SEC_data\\SEC_edgar_filings.db')\n",
    "connection1.create_folder()\n",
    "filings1 = Filing_Links(company_CIKs, filing_types, start_date, end_date)\n",
    "filings1.Get_Filing_Links()\n",
    "data1 = Extract_Data()\n",
    "data1.get_tables()\n",
    "\n",
    "# connection1 = DB_Connection(db_name, folder_path, db_path)\n",
    "# connection1.create_folder()\n",
    "# filings1 = Filing_Links(company_CIKs, filing_types, start_date, end_date)\n",
    "# filings1.Get_Filing_Links()\n",
    "# filings1.get_table_links()\n",
    "# data1 = Extract_Data()\n",
    "# data1.get_tables()\n",
    "# data1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original code:\n",
    "\"\"\" the below noptebook is a modified version of the original code from the following \n",
    "link: https://github.com/galibin24/SEC-EDGAR-python-scraper .\n",
    "\n",
    "SEC-EDGAR-python-scraper is licensed under the terms of the MIT license. \"# SEC-EDGAR-python-scraper\" \"\"\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import requests_random_user_agent # pip install requests-random-user-agent\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "import re\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import sys\n",
    "from contextlib import closing # pip install contextlib2\n",
    "import time\n",
    "from dateutil import parser # pip install python-dateutil\n",
    "from datetime import datetime\n",
    "\n",
    "''' this is where you enter in your CIK codes for the companies you want to pull data from the SEC Edgar website. \n",
    "user needs to update the database path, e'''\n",
    "# You can find company's CIK number at https://www.sec.gov/edgar/searchedgar/companysearch.html\n",
    "company_CIKs = [ticker_query]\n",
    "# Enter what forms(s) you want to extract using the '10-K', '10-Q', '8-K' format.\n",
    "filing_types = [query_report_type]\n",
    "# Enter the database name that you want to use and populate.\n",
    "#The database will be automatically created if it does not exist.\n",
    "db_name = 'SEC_edgar_filings.db'\n",
    "# Specify the folder path for DB file. For example \"C:\\sqlite\\db\"\n",
    "folder_path = db_file_path\n",
    "db_path = f\"{folder_path}\\{db_name}\"\n",
    "# Enter the date range for the filings in the 'YYYY-MM-DD' format\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-04-01'\n",
    "\n",
    "\n",
    "'''End of query input. the rest of the code will scrape the SEC Edgar website for the data you requested. create a database\n",
    "in sqlite and populate it with the data. once completed you can use the data for analysis.'''\n",
    "\n",
    "# Create a class to handle connection(s) to SQLite database(s).\n",
    "class DB_Connection:\n",
    "\n",
    "    # Initialize the object's attributes.\n",
    "    def __init__(self, db_name, folder_path, db_path):\n",
    "        self.db_name = db_name\n",
    "        self.folder_path = folder_path\n",
    "        self.db_path = db_path\n",
    "\n",
    "    # Create a directory for the DB file if the directory does not exist.\n",
    "    def create_folder(self):\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            os.makedirs(self.folder_path)\n",
    "            print(f'Successfully created a new folder path {self.folder_path}.')\n",
    "        else:\n",
    "            print(f'Folder path {self.folder_path} already exists.')\n",
    "\n",
    "    # Open connection to the database, if connection fails abort the program.\n",
    "    # If the DB file does not already exist, it will be automatically created.\n",
    "    @classmethod\n",
    "    def open_conn(cls, db_path):\n",
    "        try:\n",
    "            cls.conn = sqlite3.connect(db_path)\n",
    "            print(f'Successfully connected to the {db_path} database.')\n",
    "            return cls.conn\n",
    "        except sqlite3.Error as e:\n",
    "            print(f'Error occurred, unable to connect to the {db_path} database.\\\n",
    "                    \\n{e}\\nAbording program.')\n",
    "            # sys.exit(0) means the program is exiting without any errors\n",
    "            # sys.exit(1) means there was an error.\n",
    "            sys.exit(1)\n",
    "    # Close connection to the database.\n",
    "    @classmethod\n",
    "    def close_conn(cls):\n",
    "        try:\n",
    "            cls.conn.commit()\n",
    "            print('Committed transactions.')\n",
    "            cls.conn.close()\n",
    "            print('Closing all database connections.')\n",
    "        except Exception as e:\n",
    "            print(f'Unable to close database connection.\\n{e}')\n",
    "\n",
    "\n",
    "class Filing_Links:\n",
    "\n",
    "    def __init__(self, company_CIKs, filing_types, start_date, end_date):\n",
    "            self.company_CIKs = company_CIKs\n",
    "            # Capitalize the letters of form type, since by default SQLite is case sensitive.\n",
    "            self.filing_types = [item.upper() for item in filing_types]\n",
    "            self.start_date = start_date\n",
    "            self.end_date = end_date\n",
    "\n",
    "    # Get available filings types for a specific company and their respective links.\n",
    "    def Get_Filing_Links(self):\n",
    "        try:\n",
    "            for Company_CIK_Number in self.company_CIKs:\n",
    "                for Filing_Type in self.filing_types:\n",
    "                    # define our parameters dictionary\n",
    "                    filing_parameters = {'action':'getcompany',\n",
    "                                'CIK':Company_CIK_Number,\n",
    "                                'type':Filing_Type,\n",
    "                                'dateb':'',\n",
    "                                'owner':'exclude',\n",
    "                                'start':'',\n",
    "                                'output':'',\n",
    "                                'count':'100'}\n",
    "\n",
    "                    # request the url, and then parse the response.\n",
    "                    response = requests.get(url = r\"https://www.sec.gov/cgi-bin/browse-edgar\",\n",
    "                                            params = filing_parameters)\n",
    "                    # Add 0.1 second time delay to comply with SEC.gov's 10 requests per second limit.\n",
    "                    time.sleep(0.1)\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    # Find the document table that contains filing information.\n",
    "                    main_table = soup.find_all('table', class_='tableFile2')\n",
    "                    # The base URL will be used to construct document links URLs.\n",
    "                    sec_base_url = r\"https://www.sec.gov\"\n",
    "                    Company_Name_path=str(soup.find('span',{'class':'companyName'}))\n",
    "                    if Company_Name_path != None:\n",
    "                        try:\n",
    "                            Company_Name = re.search('<span class=\"companyName\">(.*)<acronym title',\n",
    "                                                    Company_Name_path).group(1)\n",
    "                        except AttributeError:\n",
    "                            print(\"Could not find company name, \\\n",
    "                                assigning NULL value to company name.\")\n",
    "                            Company_Name = None\n",
    "                    # loop through each row of table and extract filing numbers, links, etc.\n",
    "                    for row in main_table[0].find_all('tr'):\n",
    "                        # Your code here\n",
    "                        # find all the rows under the 'td' element.\n",
    "                        cols = row.find_all('td')\n",
    "                        # If no information was detected, move on to the next row.\n",
    "                        if len(cols) != 0:\n",
    "                            # Get the text from the table.\n",
    "                            Filing_Type = cols[0].text.strip()\n",
    "                            Filing_Date = cols[3].text.strip()\n",
    "                            Filing_Number = cols[4].text.strip()\n",
    "                            Filing_Number = ''.join(e for e in Filing_Number if e.isalnum())\n",
    "\n",
    "\n",
    "                            # Get the URL path to the filing number.\n",
    "                            filing_number_path = cols[4].find('a')\n",
    "                            if filing_number_path != None:\n",
    "                                Filing_Number_Link = sec_base_url + filing_number_path['href']\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                            # Get the URL path to the document.\n",
    "                            document_link_path = cols[1].find('a',\n",
    "                                                            {'href':True, 'id':'documentsbutton'})\n",
    "                            if document_link_path != None:\n",
    "                                Document_Link = sec_base_url + document_link_path['href']\n",
    "                            else:\n",
    "                                Document_Link = None\n",
    "\n",
    "                            # Get the account number.\n",
    "                            try:\n",
    "                                Account_Number= cols[2].text.strip()\n",
    "                                Account_Number = re.search('Acc-no:(.*)(34 Act)',\n",
    "                                                            Account_Number).group(1)\n",
    "                                Account_Number = ''.join(e for e in Account_Number if e.isalnum())\n",
    "\n",
    "                            except Exception as e:\n",
    "                                \"\"\"\n",
    "                                Add break if you don't want empty account number rows.\n",
    "                                If account number is not present, the interactive document\n",
    "                                link will not be available. If the interactive link is not\n",
    "                                present, we will not be able to extract the individual\n",
    "                                tables containing financial statements..\n",
    "                                \"\"\"\n",
    "                                Account_Number = None\n",
    "                                print(f'Could not retrieve the account number, \\\n",
    "                                        assigning NULL value.\\n{e}')\n",
    "\n",
    "                            # Get the URL path to the interactive document.\n",
    "                            interactive_data_path = cols[1].find('a',\n",
    "                                                                {'href':True, 'id':'interactiveDataBtn'})\n",
    "                            if interactive_data_path != None:\n",
    "                                Interactive_Data_Link = sec_base_url + interactive_data_path['href']\n",
    "                                # If the interactive data link exists, then so does the FilingSummary.xml link.\n",
    "                                Summary_Link_Xml = Document_Link.replace(f\"/{Account_Number}\",'')\\\n",
    "                                                                .replace('-','')\\\n",
    "                                                                .replace('index.htm' ,'/FilingSummary.xml')\n",
    "\n",
    "                            else:\n",
    "                                # break\n",
    "                                Interactive_Data_Link = None\n",
    "                                Summary_Link_Xml = None\n",
    "\n",
    "                            self.info_to_sql(Company_Name, Company_CIK_Number, Account_Number,\n",
    "                                            Filing_Type, Filing_Number, Filing_Date, Document_Link,\n",
    "                                            Interactive_Data_Link, Filing_Number_Link, Summary_Link_Xml)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not retrieve the table containing the necessary information.\\\n",
    "                    \\nAbording the program.\\nIf index list is out of range, make sure \\\n",
    "                    that you entered the correct CIK number(s).\\n{e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Migrate the DataFrame containing, filing and document links information to a local SQLite database.\n",
    "    def info_to_sql(self, Company_Name, Company_CIK_Number, Account_Number,\n",
    "                    Filing_Type, Filing_Number, Filing_Date, Document_Link,\n",
    "                    Interactive_Data_Link, Filing_Number_Link, Summary_Link_Xml):\n",
    "\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS filing_list (\n",
    "                    filing_number integer PRIMARY KEY,\n",
    "                    account_number integer,\n",
    "                    company_name text NOT NULL,\n",
    "                    cik integer NOT NULL,\n",
    "                    filing_type text NOT NULL,\n",
    "                    filing_date text NOT NULL,\n",
    "                    document_link_html TEXT NOT NULL,\n",
    "                    filing_number_link TEXT NOT NULL,\n",
    "                    interactive_dash_link TEXT,\n",
    "                    summary_link_xml TEXT\n",
    "                    )\n",
    "                    ;\"\"\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to create filing_list table.\\\n",
    "                        \\nAbording the program.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                print(\"Successfully created the table.\")\n",
    "                print(f\"Migrating information for filing number {Filing_Number} to the SQL table.......\")\n",
    "                try:\n",
    "                    # INSERT or IGNORE will insert a record if it does NOT duplicate an existing record.\n",
    "                    with closing(conn.cursor()) as cursor:\n",
    "                        cursor.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT or IGNORE INTO filing_list (\n",
    "                        filing_number,\n",
    "                        account_number,\n",
    "                        company_name,\n",
    "                        cik,\n",
    "                        filing_type,\n",
    "                        filing_date,\n",
    "                        document_link_html,\n",
    "                        filing_number_link,\n",
    "                        interactive_dash_link,\n",
    "                        summary_link_xml\n",
    "                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?) \"\"\"\n",
    "                        ,(\n",
    "                        Filing_Number,\n",
    "                        Account_Number,\n",
    "                        Company_Name,\n",
    "                        Company_CIK_Number,\n",
    "                        Filing_Type,\n",
    "                        Filing_Date,\n",
    "                        Document_Link,\n",
    "                        Filing_Number_Link,\n",
    "                        Interactive_Data_Link,\n",
    "                        Summary_Link_Xml\n",
    "                        ))\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error occurred while attempting to insert values into the filing_list table.\\n{e}\")\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "    # Extract individual table links to financial statements, supplementary data tables, etc\n",
    "    def get_table_links(self):\n",
    "        dfs = []\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                for Company_CIK_Number in self.company_CIKs:\n",
    "                    for Filing_Type in self.filing_types:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT filing_number, summary_link_xml\n",
    "                            FROM filing_list\n",
    "                            WHERE summary_link_xml IS NOT NULL\n",
    "                            AND filing_type = ?\n",
    "                            AND cik = ?\n",
    "                            AND filing_date BETWEEN ? AND ?\n",
    "                            \"\"\", con = conn , params=(Filing_Type,\n",
    "                                                    Company_CIK_Number,\n",
    "                                                    self.start_date,\n",
    "                                                    self.end_date))\n",
    "                        dfs.append(df)\n",
    "                df_query2 = pd.concat(dfs)\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to retrieve data from the filing_list table.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            # If the DataFrame is empty, terminate the program.\n",
    "            if len(df_query2) == 0:\n",
    "                print('DataFrame is empty, aborting the program.\\nAbording the program.')\n",
    "                sys.exit(1)\n",
    "            try:\n",
    "                with closing(conn.cursor()) as cursor:\n",
    "                    cursor.execute(\n",
    "                    \"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS individual_report_links (\n",
    "                    filing_number integer,\n",
    "                    short_name text,\n",
    "                    report_url text,\n",
    "                    FOREIGN KEY(filing_number) REFERENCES filing_list(filing_number),\n",
    "                    UNIQUE(report_url)\n",
    "                    )\n",
    "                    ;\"\"\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error occurred while attempting to create individual_report_links table.\\\n",
    "                        \\nAbording the program.\\n{e}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            # Extract the tables name and its respective URL\n",
    "            # Currently, I do not have a function/method to extract data from a .XML file extension.\n",
    "            for filing_number, summary_link_xml in df_query2.itertuples(index = False):\n",
    "                response_2 = requests.get(summary_link_xml).content\n",
    "                time.sleep(0.1)\n",
    "                soup_2 = BeautifulSoup(response_2, 'lxml')\n",
    "                for item in soup_2.find_all('report')[:-1]:\n",
    "                    if item.shortname:\n",
    "                        Short_Name = item.shortname.text\n",
    "                        # Remove special characters\n",
    "                        Short_Name = re.sub(r\"[^a-zA-Z0-9]+\", ' ', Short_Name)\n",
    "                        # Remove white wite space at the end of the string.\n",
    "                        Short_Name = Short_Name.rstrip()\n",
    "                    else:\n",
    "                        print('Short name could not be retrieved.')\n",
    "                        Short_Name  = None\n",
    "                    # Some tables come only in the xml form.\n",
    "                    if item.htmlfilename:\n",
    "                        Report_Url = summary_link_xml.replace('FilingSummary.xml',\n",
    "                                                            item.htmlfilename.text)\n",
    "                    elif item.xmlfilename:\n",
    "                        Report_Url = summary_link_xml.replace('FilingSummary.xml',\n",
    "                                                            item.xmlfilename.text)\n",
    "                    else:\n",
    "                        print('URL to the individual report could not be retrieved.')\n",
    "                        Report_Url = None\n",
    "                    print(Short_Name)\n",
    "                    print(Report_Url)\n",
    "                    print(filing_number)\n",
    "                    print('*'*50 + ' Inserting values into the table .... ' + '*'*50)\n",
    "                    try:\n",
    "                        with closing(conn.cursor()) as cursor:\n",
    "                            cursor.execute(\n",
    "                            \"\"\"\n",
    "                            INSERT OR IGNORE INTO individual_report_links (\n",
    "                            filing_number,\n",
    "                            short_name,\n",
    "                            report_url\n",
    "                            ) VALUES (?, ?, ?) \"\"\",(\n",
    "                            filing_number,\n",
    "                            Short_Name,\n",
    "                            Report_Url\n",
    "                            ))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error occurred while attempting to insert values into \\\n",
    "                                the individual_report_links table.\\nAbording the program.\\n{e}\")\n",
    "                        sys.exit(1)\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "\n",
    "class Extract_Data:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_xml = None\n",
    "    # Extract table data from a .XMK\n",
    "    def htm_table_extractor(self,report_url):\n",
    "        # Note to self, .text is in Unicode, .content is in bytes.\n",
    "        response_xml = requests.get(report_url).content\n",
    "        time.sleep(0.1)\n",
    "        soup_xml = BeautifulSoup(response_xml, \"lxml\")\n",
    "        table = soup_xml.find_all('table')\n",
    "        if table:\n",
    "            try:\n",
    "                print(\"Inserting table data into the DataFrame.\")\n",
    "                self.df_xml = pd.read_html(str(table))[0]\n",
    "                self.df_xml = self.df_xml.replace({'\\$':''}, regex = True)\\\n",
    "                                        .replace({'\\)':''}, regex = True)\\\n",
    "                                        .replace({'\\(':''}, regex = True)\\\n",
    "                                        .replace({'\\%':''}, regex = True)\\\n",
    "                                        .replace({' ','', 1}, regex = True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error occurred while attempting to insert \\\n",
    "                        table data into the DataFrame.\\n{e}')\n",
    "        else:\n",
    "            print(f'No table detected for {report_url}.')\n",
    "\n",
    "    # Retreive the necessary information information to extract data from the table's URL.\n",
    "    def get_tables(self):\n",
    "\n",
    "        dfs =[]\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            for company_CIK in filings1.company_CIKs:\n",
    "                for filing_type in filings1.filing_types:\n",
    "                    try:\n",
    "                        df = pd.read_sql_query(\n",
    "                            \"\"\"\n",
    "                            SELECT a.filing_number,\n",
    "                                a.company_name,\n",
    "                                a.filing_type,\n",
    "                                a.filing_date,\n",
    "                                b.short_name ,\n",
    "                                b.report_url\n",
    "                            FROM filing_list a\n",
    "                            INNER JOIN individual_report_links b\n",
    "                            ON a.filing_number = b.filing_number\n",
    "                            WHERE b.report_url LIKE '%.htm%'\n",
    "                            AND a.cik = ?\n",
    "                            AND a.filing_type = ?\n",
    "                            AND a.filing_date BETWEEN ? AND ?\n",
    "                            ORDER by filing_date DESC\n",
    "                            LIMIT ?\n",
    "                            \"\"\", con = conn , params=(company_CIK, filing_type,\n",
    "                                                    filings1.start_date,\n",
    "                                                    filings1.end_date , 10))\n",
    "                        dfs.append(df)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error occurred while attempting to retreive data \\\n",
    "                                from the SQL database.\\nAbording the program.\\n{e}\")\n",
    "                        sys.exit(1)\n",
    "            df_query1 = pd.concat(dfs)\n",
    "            # If the DataFrame is empty, terminate the program.\n",
    "            if len(df_query1) == 0:\n",
    "                print('DataFrame is empty, aborting the program.\\nAbording the program.')\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                # If maximum recursion error occurs, increase recursion limit. sys.setrecursionlimit(25000)\n",
    "                pass\n",
    "            for filing_number,\\\n",
    "                company_name,\\\n",
    "                filing_type,\\\n",
    "                filing_date,\\\n",
    "                short_name,\\\n",
    "                report_url in df_query1.itertuples(index = False):\n",
    "                print(f'Processing {short_name} table at {report_url}.')\n",
    "\n",
    "                if report_url.endswith('.htm'):\n",
    "                    try:\n",
    "                        self.htm_table_extractor(report_url)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Could not retreive the table for filing number \\\n",
    "                                {filing_number} at {report_url}\\n{e}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        try:\n",
    "                            # We want to name the table with a unique table name for easy reference.\n",
    "                            table_name = filing_type + filing_date + '_' + \\\n",
    "                                        short_name.replace(' ','_') + '_' + str(filing_number)\n",
    "                            # Remove all special characters except for '_'\n",
    "                            table_name = re.sub(r\"[^a-zA-Z0-9]+\", '_', table_name)\n",
    "                            print(f'Inserting data from the DataFrame into SQL table {table_name}')\n",
    "                            # Check to see if table already exists in the database to avoid duplicate records.\n",
    "                            with closing(conn.cursor()) as cursor:\n",
    "                                cursor.execute(f\"\"\" SELECT count(name)\n",
    "                                            FROM sqlite_master\n",
    "                                            WHERE type='table' AND name= '{table_name}' \"\"\") # SQL injection vulnerability.\n",
    "                                # If count is 1, then table exists\n",
    "                                if cursor.fetchone()[0]==1:\n",
    "                                    print(f'Table {table_name} already exists.')\n",
    "                                else:\n",
    "                                    # Write records that are stored in the DataFrame into a SQL server database.\n",
    "                                    self.df_xml.to_sql(con = conn,\n",
    "                                            name=table_name,\n",
    "                                            schema='SCHEMA',\n",
    "                                            index=False,\n",
    "                                            if_exists='fail')\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Could not migrate the {short_name} table to the SQL database.\\n{e}\")\n",
    "                elif report_url.endswith('.xml'):\n",
    "                    print('.xml extension link detected. Unable to to process the table.\\\n",
    "                        \\n.xml extension link support is expected to be developed in the future.')\n",
    "                else:\n",
    "                    print(f'Table for filing number {filing_number} could not be detected.')\n",
    "\n",
    "        DB_Connection.close_conn()\n",
    "\n",
    "\n",
    "    # Normalize the data.\n",
    "    def transpose(self):\n",
    "\n",
    "        db2_path = db_path.replace('.db','_transposed.db')\n",
    "        with DB_Connection.open_conn(db_path) as conn:\n",
    "            try:\n",
    "                df_table_list = pd.read_sql_query(\n",
    "                \"\"\"\n",
    "                SELECT name AS table_name\n",
    "                FROM sqlite_master\n",
    "                WHERE type='table'\n",
    "                \"\"\", conn)\n",
    "            except ValueError as e:\n",
    "                print(f\"Could not retrieve table list.\\n{e}\")\n",
    "            for row in df_table_list.itertuples(index = False):\n",
    "                try:\n",
    "                    df_table = pd.read_sql_query(\n",
    "                    \"\"\" SELECT * FROM \"{}\" \"\"\".format(row.table_name), con=conn)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Could not read table {table_name}.\\n{e}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        while row.table_name not in ['filing_list', 'individual_report_links']:\n",
    "                            # Remove duplicate rows that have the same values.\n",
    "                            df_table = df_table.drop_duplicates()\n",
    "                            # Transpose the pandas DataFrame.\n",
    "                            df_table = df_table.T\n",
    "                            # Transform first rows into the header.\n",
    "                            df_table.columns = df_table.iloc[0]\n",
    "                            df_table = df_table[1:]\n",
    "                            # Remove special characters, replace empty spaces with _\n",
    "                            df_table = df_table.rename(columns=lambda x: re.sub('\\W+','_',str(x)))\n",
    "                            df_table.columns = df_table.columns.str.strip('_')\n",
    "                            df_table.columns = df_table.columns.str.lower()\n",
    "                            # Convert index of the DataFrame into a column.\n",
    "                            df_table.reset_index(level=0, inplace=True)\n",
    "                            # Format the date column.\n",
    "                            try:\n",
    "                                date_list = []\n",
    "                                for item in df_table.iloc[:,0]:\n",
    "                                    match = re.search('\\D{3}. \\d{2}, \\d{4}', item)\n",
    "                                    if match is not None:\n",
    "                                        # .strftime removes the time stamp.\n",
    "                                        date= parser.parse(match.group()).strftime(\"%Y-%m-%d\")\n",
    "                                        date_list.append(date)\n",
    "                                    else:\n",
    "                                        date_list.append(item)\n",
    "                                df_table.rename(columns={ df_table.columns[0]: \"date\" }, inplace = True)\n",
    "                                df_table['date'] = date_list\n",
    "                                print('Successfully formatted the date.')\n",
    "                            except Exception as e:\n",
    "                                df_table.rename(columns={ df_table.columns[0]: \"name\" }, inplace = True)\n",
    "                                print(e)\n",
    "\n",
    "                            # Convert rows to numeric data types such as integers and floats.\n",
    "                            df_table.replace(',','', regex=True, inplace=True)\n",
    "                            df_table = df_table.apply(pd.to_numeric, errors = 'ignore')\n",
    "                            # Dynamically rename duplicate rows that have the same name.\n",
    "                            if any(df_table.columns.duplicated()):\n",
    "                                print('Duplicate column name detected.\\nRenaming the duplicate column name.  ')\n",
    "                                columns_series = pd.Series(df_table.columns)\n",
    "                                for dup in columns_series[columns_series.duplicated()].unique():\n",
    "                                    columns_series[columns_series[columns_series == dup].index.values.tolist()] = \\\n",
    "                                    [dup + '.' + str(i) if i != 0 else dup for i in range(sum(columns_series == dup))]\n",
    "                                df_table.columns = columns_series\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not transpose the table.\\n{e}\")\n",
    "                    else:\n",
    "                        with DB_Connection.open_conn(db2_path) as conn2:\n",
    "                            # Check to see if table already exists in the database.\n",
    "                            with closing(conn2.cursor()) as cursor:\n",
    "                                cursor.execute(f\"\"\" SELECT count(name)\n",
    "                                            FROM sqlite_master\n",
    "                                            WHERE type='table' AND name= '{row.table_name}' \"\"\") # SQL injection vulnerability.\n",
    "                                # If count is 1, then table exists\n",
    "                                if cursor.fetchone()[0]==1 and row.table_name not in ['filing_list', 'individual_report_links']:\n",
    "                                    print(f'Table {row.table_name} already exists.')\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        print(f'Connected to the {db2_path} database.')\n",
    "                                        print(f'Inserting data from the DataFrame into SQL table {row.table_name}')\n",
    "                                        # Write records that are stored in the DataFrame into a SQL server database.\n",
    "                                        df_table.to_sql(con = conn2,\n",
    "                                                        name = row.table_name,\n",
    "                                                        schema ='SCHEMA',\n",
    "                                                        if_exists = 'replace',\n",
    "                                                        index = False\n",
    "                                                        )\n",
    "\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Could not migrate the {row.table_name} table to the normalized SQL database.\\n{e}\")\n",
    "        DB_Connection.close_conn()\n",
    "# copilot correction, added the following code to convert the company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "# # Convert company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "# company_CIKs = str(company_CIKs) if isinstance(company_CIKs, list) else company_CIKs\n",
    "# filing_types = str(filing_types) if isinstance(filing_types, list) else filing_types\n",
    "# start_date = str(start_date) if isinstance(start_date, list) else start_date\n",
    "# end_date = str(end_date) if isinstance(end_date, list) else end_date\n",
    "\n",
    "\n",
    "# Convert company_CIKs, filing_types, start_date, and end_date to strings if they are lists\n",
    "company_CIKs = str(company_CIKs) if isinstance(company_CIKs, list) else company_CIKs\n",
    "filing_types = str(filing_types) if isinstance(filing_types, list) else filing_types\n",
    "start_date = str(start_date) if isinstance(start_date, list) else start_date\n",
    "end_date = str(end_date) if isinstance(end_date, list) else end_date\n",
    "\n",
    "connection1 = DB_Connection(db_name, folder_path, db_path)\n",
    "connection1.create_folder()\n",
    "filings1 = Filing_Links(company_CIKs, filing_types, start_date, end_date)\n",
    "filings1.Get_Filing_Links()\n",
    "filings1.get_table_links()\n",
    "data1 = Extract_Data()\n",
    "data1.get_tables()\n",
    "data1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
