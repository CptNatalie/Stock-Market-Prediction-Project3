{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from datetime import timedelta, datetime\n",
    "import plotly.graph_objs as go\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#building the url with the API Key needed to \n",
    "def urlBuilder(ticker, functionType, outputSize):\n",
    "    load_dotenv(r'Index_Fund_AI_Anaysis_App_Prj_3\\Resourses_Prj_3\\.env')\n",
    "    api_key =  os.getenv(\"extraKey\")\n",
    "    url = \"https://www.alphavantage.co/query?\"\n",
    "    if(functionType != None):\n",
    "        url = url + f\"function={functionType}\"\n",
    "    if(ticker != None):\n",
    "        if(functionType == \"NEWS_SENTIMENT\"):\n",
    "            url = url + f\"&tickers={ticker}&limit=1000\"\n",
    "        else:\n",
    "            url = url + f\"&symbol={ticker}\"\n",
    "    if(outputSize != None):\n",
    "        url = url + f\"&outputsize={outputSize}\"\n",
    "    url = url + f\"&apikey={api_key}\"\n",
    "    print(url)\n",
    "    return url\n",
    "\n",
    "\n",
    "#API call\n",
    "def loadData(ticker):\n",
    "    functionType = 'TIME_SERIES_DAILY'\n",
    "    interval = 'Daily'\n",
    "    outputsize = 'full'\n",
    "    url = urlBuilder(ticker, functionType, outputsize)\n",
    "    # Get the response\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    # Extract time series data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract time series data\n",
    "    time_series_data = data.get('Time Series (Daily)', {})\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(time_series_data).T\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "    # Convert data types\n",
    "    df = df.astype({\"open\": float, \"high\": float, \"low\": float, \"close\": float, \"volume\": int})\n",
    "\n",
    "    # Convert index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Sort index\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'date'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def loadPreSavedData(file_path):\n",
    "    # Reading in the CSV about the stock data from the local repo\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Convert the 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def loadNewsSentiments(ticker):\n",
    "    functionType = 'NEWS_SENTIMENT'\n",
    "    url = urlBuilder(ticker, functionType, None)\n",
    "    \n",
    "    # Get the response\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    # Extract time series data\n",
    "    news_feed = data.get(f'feed', {})\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(news_feed)\n",
    "    df = df[['title', 'time_published', 'summary', 'overall_sentiment_score']]\n",
    "    df['time_published'] = df['time_published'].str.split('T').str[0]\n",
    "    # Convert the 'time_published' column to datetime\n",
    "    df['time_published'] = pd.to_datetime(df['time_published'])\n",
    "\n",
    "    # Format the date as YYYY-MMM-DD\n",
    "    df['time_published'] = df['time_published'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    df_grouped = df.groupby('time_published').agg({\n",
    "        'title': lambda x: ', '.join(x),\n",
    "        'summary': lambda x: ', '.join(x),\n",
    "        'overall_sentiment_score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_grouped.columns = [\"date\", \"title\", \"summary\", \"sentiment\"]\n",
    "    \n",
    "    # Convert index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Sort index\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'date'}, inplace=True)\n",
    "    \n",
    "    return df_grouped\n",
    "\n",
    "# Prediction Function\n",
    "def regression_predictions(df):\n",
    "    X=df.drop(columns=['target','tomorrow','close','date'], axis=1)\n",
    "    y1=df['close']\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.3, random_state=42)\n",
    "    \n",
    "    #fit training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X1_train,y1_train)\n",
    "    \n",
    "    # Make predictions on testing data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    df['y_pred_LR'] = y_pred\n",
    "    \n",
    "    model = ExtraTreesRegressor()\n",
    "    model.fit(X1_train,y1_train)\n",
    "    \n",
    "    # Make predictions on testing data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    df['y_pred_ETR'] = y_pred\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X1_train,y1_train)\n",
    "    \n",
    "    # Make predictions on testing data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    df['y_pred_RFG'] = y_pred\n",
    "    \n",
    "    model = AdaBoostRegressor()\n",
    "    model.fit(X1_train,y1_train)\n",
    "    \n",
    "    # Make predictions on testing data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    df['y_pred_ABR'] = y_pred\n",
    "    \n",
    "    return df\n",
    "\n",
    "def graph_preds(df, ticker):\n",
    "    # Visualization\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df['y_pred'], mode='lines', name='Predicted Price'))\n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df['close'], mode='lines', name='Actual Price'))\n",
    "    # fig.add_trace(go.Scatter(x=df['date'], y=df['y_pred_LR'], mode='lines', name='LR model'))\n",
    "    fig.update_layout(title=f'Stock Prices and Predictions for {ticker}',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Price')\n",
    "    fig.show()\n",
    "    \n",
    "def preds_output(df):\n",
    "    num_shares = int(input(\"Enter the number of shares owned: \"))\n",
    "    investment_amount = float(input(\"Enter how much you have to invest: \"))\n",
    "    trend = 'higher' if df['close'].iloc[-1] > df['y_pred'].iloc[-1] else 'lower'\n",
    "    action = 'buy' if trend == 'higher' else 'sell'\n",
    "    optimal_volume = min(investment_amount / df['y_pred'].iloc[-1], num_shares)\n",
    "    investment_value = df['close'].iloc[-1] * num_shares  # This is speculative\n",
    "    \n",
    "    print(f\"Future predicted price for tomorrow: {df['close'].iloc[-1]}\")\n",
    "    print(f\"The trend for the future price is {trend}.\")\n",
    "    print(f\"You should {action}.\")\n",
    "    print(f\"The optimal volume to {action} is {optimal_volume} shares.\")\n",
    "    print(f\"The speculative future value of your investment is: ${investment_value:.2f}.\")\n",
    "    print(\"Please note, this is a prediction based on historical data and carries risk.\")\n",
    "    \n",
    "def save_plot_as_image(df, company):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df['close'], mode='lines', name='Close Price'))\n",
    "    fig.update_layout(title=f'Stock Prices for {company}',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Price')\n",
    "    # Save the plot as an image\n",
    "    image_file = f\"Resources/outputs/plot_{company}.png\"\n",
    "    fig.write_image(image_file)\n",
    "    print(f\"Plot saved as {image_file}\")\n",
    "\n",
    "    \n",
    "def run(company, ticker):\n",
    "    \n",
    "    file_path = f'Resources/alphavantage/{ticker.lower()}.csv'\n",
    "    # Index_Fund_Price_Prediction_App/Resources/alphavantage/ibm.csv\n",
    "    print(file_path)\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"Pulling from local storage\")\n",
    "        df_stock = loadPreSavedData(file_path)\n",
    "    else:\n",
    "        print(\"Pulling new data from AlphaVantage\")\n",
    "        df_stock = loadData(ticker)\n",
    "        df_news = loadNewsSentiments(ticker)    \n",
    "        print(df_stock.head())\n",
    "        print(df_news.head())\n",
    "        \n",
    "        df_news['date'] = pd.to_datetime(df_news['date'])\n",
    "        \n",
    "        # Merge the DataFrames on the 'date' column\n",
    "        merged_df = pd.merge(df_stock, df_news, on='date', how='left')\n",
    "        # Display the merged DataFrame\n",
    "        print(merged_df.head())\n",
    "        print(merged_df.tail())\n",
    "        \n",
    "        # Save the merged DataFrame as a CSV file with a specific path\n",
    "        merged_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    company = \"Apple\"\n",
    "    ticker = input(\"Enter a stock ticker: \").upper()\n",
    "    run(company, ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
